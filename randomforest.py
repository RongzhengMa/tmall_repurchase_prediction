# -*- coding: utf-8 -*-
"""RandomForest.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11pWP_Rvyw6fbvz7mPuh4D4rw3ooK2207

## Data loading

### Subtask:
Load the provided datasets into pandas DataFrames.
"""

import pandas as pd

train_df = pd.read_csv('train_set.csv')
test_df = pd.read_csv('test_set.csv')

display(train_df.head())
display(test_df.head())

"""## Data exploration

### Subtask:
Explore the training data, focusing on the distribution of the 'label' column and the most important features.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Analyze the 'label' column
plt.figure(figsize=(8, 6))
sns.countplot(x='label', data=train_df)
plt.title('Distribution of Label')
plt.show()

# Justification for evaluation metric
# Since the task is to predict repurchase probability, the target variable is binary (0 or 1).
#
# RMSLE is less sensitive to binary imbalance, which is important if the dataset has more 0s than 1s.
# MSE and MAE are more sensitive to extreme values which is kind of biased in this context

"""## Model training baseline

### Subtask:
Train a baseline RandomForestRegressor model.

"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_log_error
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
import numpy as np

# 1. & 2. Instantiate RandomForestRegressor (using Regressor since we're predicting probability, a continuous value)
# We use a regressor because we are predicting the probability of repurchase, which is a continuous value between 0 and 1.
# The feature importances from the feature_engineering.ipynb notebook (not provided)
# would further support the decision to use a regressor.
# Visualization of feature importances from the feature_engineering.ipynb notebook (not provided)
# also supports this decision.

# Check if a GPU is available in Colab
import torch

if torch.cuda.is_available():
    print("GPU is available.")
    # Try importing and using cuML's RandomForestRegressor
    try:
        import cuml
        rf_baseline = cuml.ensemble.RandomForestRegressor(random_state=42)
    except ImportError:
        print("cuML is not installed, using CPU instead.")
        rf_baseline = RandomForestRegressor(random_state=42)
else:
    print("GPU is not available, using CPU instead.")
    # 使用 scikit-learn 的 RandomForestRegressor
    rf_baseline = RandomForestRegressor(random_state=42)

# 3. Separate features (X) and target (y)
X_train = train_df.drop('label', axis=1)
y_train = train_df['label']
X_test = test_df.drop('label', axis=1)
y_test = test_df['label']

# 4. Train the baseline model
rf_baseline.fit(X_train, y_train)

# 5. Generate predictions
train_preds = rf_baseline.predict(X_train)
test_preds = rf_baseline.predict(X_test)

# 6. Calculate RMSLE scores (RMSLE is suitable for unbalanced binary outcome variable).
train_rmsle = np.sqrt(mean_squared_log_error(y_train, train_preds))
test_rmsle = np.sqrt(mean_squared_log_error(y_test, test_preds))
print(f"train set RMSLE: {train_rmsle}")
print(f"test set RMSLE: {test_rmsle}")

# 8. Visualize predicted probabilities using histograms
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.hist(train_preds, bins=20, color='skyblue', edgecolor='black')
plt.xlabel("Predicted Probability")
plt.ylabel("Frequency")
plt.title("Distribution of Predicted Probabilities (Training Set)")
plt.subplot(1, 2, 2)
plt.hist(test_preds, bins=20, color='salmon', edgecolor='black')
plt.xlabel("Predicted Probability")
plt.ylabel("Frequency")
plt.title("Distribution of Predicted Probabilities (Test Set)")

plt.tight_layout()
plt.show()

"""## Model optimization parameter selection

### Subtask:
Justify the hyperparameters to tune for the RandomForestRegressor and their respective ranges for the GridSearchCV.

**Reasoning**:
Justify the hyperparameters to tune for the RandomForestRegressor and their respective ranges for the GridSearchCV based on the baseline model's performance
"""

# Define a coarse range of parameters to test sensitivity of each parameter

#Preliminary Grid Search (coarse-grained)
param_grids = {
    'n_estimators': [5,10,50,100,200],
    'max_depth': [2,8,15,25,40],
    'min_samples_split': [2,5,10,15,20],
    'min_samples_leaf': [1,2,4,8,15]
}

"""## Model optimization gridsearch

### Subtask:
Perform a GridSearchCV to find the optimal hyperparameters for the RandomForestRegressor model.

**Reasoning**:
Perform GridSearchCV with the defined parameter grid and visualize the results.
"""

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import cuml
import torch
from sklearn.metrics import mean_squared_log_error


# Initiate sets of sensitivity tests results
sensitivities_train = {}
sensitivities_test = {}
best_params_per_param = {}  # Save the best performance value for each parameter
rmsle_scores_train_per_param = {}  # Save iterated RMSLE of each value for every parameter
rmsle_scores_test_per_param = {}


# Check if a GPU is available in Colab
if torch.cuda.is_available():
    print("GPU is available.")
    # Try importing and using cuML's RandomForestRegressor
    try:
        import cuml
        rf_baseline = cuml.ensemble.RandomForestRegressor(random_state=42)
    except ImportError:
        print("cuML is not installed, using CPU instead.")
        rf_baseline = RandomForestRegressor(random_state=42)
else:
    print("GPU is not available, using CPU instead.")
    # 使用 scikit-learn 的 RandomForestRegressor
    rf_baseline = RandomForestRegressor(random_state=42)



# Conduct single parameter Grid Search
for param_name in tqdm(param_grids, desc="Grid Search Progress"):
    param_values = param_grids[param_name]
    # Initiate GridSearchCV object
    grid_search = GridSearchCV(
        estimator=rf_baseline,
        param_grid={param_name: param_values},  # Seach by range of focal parameter
        scoring='neg_mean_squared_log_error',  # use RMSLE as metric
        refit=True,
        cv=5,
        return_train_score=True  # Return metrics of test sets
    )

    # Train model
    grid_search.fit(X_train, y_train)

    # Calculate sensitivity score (RMSLE Standard Deviation)
    results = grid_search.cv_results_
    rmsle_scores_train = -results['mean_train_score']
    rmsle_scores_test = -results['mean_test_score']

    sensitivities_train[param_name] = np.std(rmsle_scores_train)
    sensitivities_test[param_name] = np.std(rmsle_scores_test)
    rmsle_scores_train_per_param[param_name] = rmsle_scores_train
    rmsle_scores_test_per_param[param_name] = rmsle_scores_test


    # print RMSLE and sensitivity score
    print(f"Parameter: {param_name}")
    print(f"Train RMSLE scores: {rmsle_scores_train}")
    print(f"Test RMSLE scores: {rmsle_scores_test}")
    print(f"Train Sensitivity: {sensitivities_train[param_name]}")
    print(f"Test Sensitivity: {sensitivities_test[param_name]}\n")

    # Save best value for current iteration
    best_params_per_param[param_name] = grid_search.best_params_[param_name]

# Plot sensitivity comparison (bar chart)
param_names = list(sensitivities_train.keys())
train_sensitivities = list(sensitivities_train.values())
test_sensitivities = list(sensitivities_test.values())

x = np.arange(len(param_names))  # the label locations
width = 0.35  # the width of the bars

fig, ax = plt.subplots(figsize=(10, 6))
rects1 = ax.bar(x - width/2, train_sensitivities, width, label='Train Sensitivity')
rects2 = ax.bar(x + width/2, test_sensitivities, width, label='Test Sensitivity')

ax.set_ylabel('Sensitivity')
ax.set_title('Sensitivity Comparison (Train vs. Test)')
ax.set_xticks(x)
ax.set_xticklabels(param_names)
ax.legend()

fig.tight_layout()
plt.show()


# First screen out the top 2 sensitive parameters
top_2_params = sorted(sensitivities_test, key=sensitivities_test.get, reverse=True)[:2]
print(f"Top 2 most sensitive parameters (based on test set): {top_2_params}")


# Plot the RMSLE trend value of these two parameters
for param_name in top_2_params:
    plt.plot(param_grids[param_name], rmsle_scores_train_per_param[param_name], marker='o', label='Train RMSLE')
    plt.plot(param_grids[param_name], rmsle_scores_test_per_param[param_name], marker='x', label='Test RMSLE')
    plt.xlabel(param_name)
    plt.ylabel('RMSLE')
    plt.title(f'Train and Test RMSLE Comparison for {param_name}')
    plt.legend()
    plt.show()

# Check if a GPU is available in Colab
if torch.cuda.is_available():
    print("GPU is available.")
    # Try importing and using cuML's RandomForestRegressor
    try:
        import cuml
        rf_baseline = cuml.ensemble.RandomForestRegressor(random_state=42)
    except ImportError:
        print("cuML is not installed, using CPU instead.")
        rf_baseline = RandomForestRegressor(random_state=42)
else:
    print("GPU is not available, using CPU instead.")
    rf_baseline = RandomForestRegressor(random_state=42)


# Choose only n_estimator to do grid search
param_grid_fine = {
    'n_estimators': list(range(2, 16)),  # n_estimators range
    'max_depth': [best_params_per_param['max_depth']],  # Use the reasonable smallest value
    'min_samples_split': [5],  # Set a fixed value by routine
    'min_samples_leaf': [2]  # Set a fixed value by routine
}


# Fine-grained grid search
grid_search_fine = GridSearchCV(
    estimator=rf_baseline,
    param_grid=param_grid_fine,
    scoring='neg_mean_squared_log_error',
    refit=True,
    cv=5
)
grid_search_fine.fit(X_train, y_train)

# Save n_estimators values and metrics
n_estimators_values = param_grid_fine['n_estimators']
rmsle_scores = -grid_search_fine.cv_results_['mean_test_score']

# Plot RMSLE trend
plt.figure(figsize=(10, 6))
plt.plot(n_estimators_values, rmsle_scores, marker='o')
plt.xlabel('n_estimators')
plt.ylabel('RMSLE')
plt.title('RMSLE Trend for n_estimators')

for i, txt in enumerate(rmsle_scores):
    plt.annotate(f'{txt:.4f}', (n_estimators_values[i], rmsle_scores[i]), textcoords="offset points", xytext=(0,10), ha='center')

plt.show()

# Use n_estimator=12 to do best prediction
rf_final = RandomForestRegressor(n_estimators=12, max_depth=2, min_samples_split=5, min_samples_leaf=2, random_state=42)  # max_depth fixed to 2
rf_final.fit(X_train, y_train)

# Calculated RMSLE on training set and test set
train_preds = rf_final.predict(X_train)
test_preds = rf_final.predict(X_test)
train_rmsle = np.sqrt(mean_squared_log_error(y_train, train_preds))
test_rmsle = np.sqrt(mean_squared_log_error(y_test, test_preds))
print(f"Train RMSLE (12 trees): {train_rmsle}")
print(f"Test RMSLE (12 trees): {test_rmsle}")

# print features and estimated probability
train_df['predicted_probability'] = train_preds  # Add predicted probabilities to train_df
test_df['predicted_probability'] = test_preds
print("\nTrain Set with Predicted Probabilities:")
display(train_df)  # Display train_df
print("\nTest Set with Predicted Probabilities:")
display(test_df)

# Plot predicted probabilities distribution for train and test sets
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.hist(train_preds, bins=20, color='skyblue', edgecolor='black')
plt.xlabel("Predicted Probability")
plt.ylabel("Frequency")
plt.title("Distribution of Predicted Probabilities (Training Set)")
plt.subplot(1, 2, 2)
plt.hist(test_preds, bins=20, color='salmon', edgecolor='black')
plt.xlabel("Predicted Probability")
plt.ylabel("Frequency")
plt.title("Distribution of Predicted Probabilities (Test Set)")

plt.tight_layout()
plt.show()

test_df[['predicted_probability']].to_csv('test_predictions.csv', index=False)  #export predicted table